# Analisador L√©xico para SPARQL

## TPC4
Este trabalho de casa implementa um **analisador l√©xico para consultas SPARQL** em Python.  
O analisador reconhece os seguintes elementos da linguagem:

- **Palavras reservadas** (`SELECT`, `WHERE`, `LIMIT`, `FILTER`, `OPTIONAL`, `ORDER BY`, `GROUP BY`)
- **Vari√°veis** (ex: `?nome`, `?desc`)
- **URIs** (ex: `dbo:MusicalArtist`, `foaf:name`)
- **Literais** (ex: `"Chuck Berry"@en`)
- **N√∫meros** (ex: `1000`)
- **Operadores** (`{}`, `.`, `,`, `()`)

O programa l√™ um ficheiro SPARQL e gera um ficheiro de sa√≠da contendo a lista de tokens reconhecidos.

---

## Como Utilizar
### **Executar o Analisador L√©xico**
1. Colocar a consulta SPARQL no ficheiro `teste.txt` ou utilizar a que j√° est√° presente neste.
2. Executar o analisador l√©xico:
   ```sh
   python3 LEXtpc4.py
   ```
3. O output ser√° gerado no ficheiro `LEXresultados.txt`, contendo os tokens reconhecidos.

### **Alternativa com Express√µes Regulares**
Para testar a vers√£o alternativa, que utiliza apenas express√µes regulares:
```sh
python3 tpc4.py
```
O output ser√° gerado no ficheiro `resultados.txt`.

---

## Estrutura do C√≥digo

### **Leitura do Ficheiro de Entrada**
O programa l√™ o conte√∫do de `teste.txt` e processa cada linha para identificar os tokens.

### **Express√µes Regulares Utilizadas**
As express√µes regulares s√£o usadas para identificar os diferentes tipos de tokens:

- **Palavras reservadas**:
  ```python
  r'\b(SELECT|WHERE|LIMIT|FILTER|OPTIONAL|ORDER BY|GROUP BY)\b'
  ```
Reconhece palavras reservadas SPARQL em mai√∫sculas ou min√∫sculas.

- **Vari√°veis**:
  ```python
  r'\?\w+'
  ```
Captura vari√°veis SPARQL que come√ßam com ?.

- **URIs**:
  ```python
  r'\b[a-zA-Z_][\w-]*:[\w-]+\b'
  ```
Reconhece URIs como dbo:MusicalArtist.

- **Literais**:
  ```python
  r'"[^"]*"(@[a-z]+)?'
  ```
Captura literais de texto, como "Chuck Berry"@en.

- **N√∫meros**:
  ```python
  r'\b\d+\b'
  ```
Reconhece n√∫meros inteiros isolados.

- **Operadores**:
  ```python
  r'[{}.,()]''
  ```
Reconhece {}, ., ,, ().

---

## Exemplo de Entrada e Sa√≠da
### Entrada (teste.txt)
  ```sparql
  # DBPedia: obras de Chuck Berry
    SELECT ?nome ?desc WHERE {
    ?s a dbo:MusicalArtist.
    ?s foaf:name "Chuck Berry"@en .
    ?w dbo:artist ?s.
    ?w foaf:name ?nome.
    ?w dbo:abstract ?desc
  } LIMIT 1000
  ```

### Sa√≠da (LEXresultados.txt ou resultados.txt)
  ```plaintext
  ('KEYWORD', 'select', 1, (0, 6))
  ('VAR', '?nome', 1, (7, 12))
  ('VAR', '?desc', 1, (13, 18))
  ('KEYWORD', 'where', 1, (19, 24))
  ('OP', '{', 1, (25, 26))
  ('VAR', '?s', 2, (27, 29))
  ('TYPE', 'a', 2, (30, 31))
  ('URI', 'dbo:MusicalArtist', 2, (32, 49))
  ('OP', '.', 2, (49, 50))
  ('VAR', '?s', 3, (51, 53))
  ('URI', 'foaf:name', 3, (54, 63)) 
  ('LITERAL', '"Chuck Berry"@en', 3, (64, 80))
  ('OP', '.', 3, (81, 82))
  ('VAR', '?w', 4, (83, 85))
  ('URI', 'dbo:artist', 4, (86, 96))
  ('VAR', '?s', 4, (97, 99))
  ('OP', '.', 4, (99, 100))
  ('VAR', '?w', 5, (101, 103))
  ('URI', 'foaf:name', 5, (104, 113))
  ('VAR', '?nome', 5, (114, 119))
  ('OP', '.', 5, (119, 120))
  ('VAR', '?w', 6, (121, 123))
  ('URI', 'dbo:abstract', 6, (124, 136))
  ('VAR', '?desc', 6, (137, 142))
  ('OP', '}', 7, (143, 144))
  ('KEYWORD', 'limit', 7, (145, 150))
  ('NUM', 1000, 7, (151, 155))
  ```

---

## Diferen√ßas entre `LEXtpc4.py` e `tpc4.py`
O trabalho de casa tem **duas vers√µes** do analisador l√©xico:

| Vers√£o      | Implementa√ß√£o        | Output |
|------------|---------------------|--------|
| `tpc4.py`  | **Baseada em `re`** (express√µes regulares) | `resultados.txt` |
| `LEXtpc4.py` | **Baseada em `ply.lex`** (biblioteca de an√°lise l√©xica) | `LEXresultados.txt` |

Ambas as vers√µes fazem a mesma an√°lise, mas `LEXtpc4.py` usa um **analisador l√©xico estruturado**, enquanto `tpc4.py` usa apenas **express√µes regulares**.

---

## üìÅ Estrutura do Projeto  

```bash
üìÇ TPC4
 ‚îú‚îÄ‚îÄ üìÑ LEXtpc4.py         # Vers√£o do analisador l√©xico com `ply.lex`
 ‚îú‚îÄ‚îÄ üìÑ tpc4.py            # Vers√£o do analisador l√©xico baseada em express√µes regulares
 ‚îú‚îÄ‚îÄ üìÑ teste.txt          # Ficheiro de entrada com a consulta SPARQL
 ‚îú‚îÄ‚îÄ üìÑ LEXresultados.txt  # Sa√≠da da vers√£o `LEXtpc4.py`
 ‚îú‚îÄ‚îÄ üìÑ resultados.txt     # Sa√≠da da vers√£o `tpc4.py`
 ‚îú‚îÄ‚îÄ üìÑ README.md          # Documenta√ß√£o do projeto
```
---

## üéØ Conclus√£o  

Este projeto implementa um **analisador l√©xico para SPARQL**, permitindo identificar e classificar corretamente os tokens presentes em consultas SPARQL. 

‚úÖ **Resumo dos Objetivos Cumpridos:**  
‚úîÔ∏è Identifica√ß√£o de **palavras-chave** (constantes do tipo string), como `SELECT`, `WHERE`, `LIMIT`, `FILTER`, `OPTIONAL`, `ORDER BY`, `GROUP BY`.  
‚úîÔ∏è Identifica√ß√£o de **sinais** (constitu√≠dos apenas por 1 car√°cter), como `{`, `}`, `.`, `,`, `(`, `)`.  
‚úîÔ∏è Identifica√ß√£o de **s√≠mbolos terminais vari√°veis**:  
  **Vari√°veis**: tokens do tipo `?nome`, `?desc`.  
  **N√∫meros**: tokens que representam n√∫meros inteiros, como `1000`.  
  **URIs**: tokens que representam URIs, como `dbo:MusicalArtist` ou `foaf:name`.  
  **Literais**: tokens que representam literais de texto, como `"Chuck Berry"@en`.  
‚úîÔ∏è Uso de duas abordagens: **express√µes regulares (`re`)** e **biblioteca `ply.lex`**.  
‚úîÔ∏è Ficheiros de sa√≠da com os tokens analisados (`LEXresultados.txt` e `resultados.txt`).  

---

## Identifica√ß√£o
**Nome:** Sara Azevedo Lopes  
**N√∫mero de Aluno:** 104179

![Identifica√ß√£o Sara Azevedo Lopes](../fotografia.png)
